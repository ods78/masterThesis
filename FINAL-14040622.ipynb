{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79223d-477a-4245-a8d2-1bf0c7797015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d484e7-bfad-4adb-bab0-b37440d77e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMBINE MULTIPLE YEAR DATA FILES WITH UNIQUE PATIENT IDENTIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMBINING MULTI-YEAR MEDICAL DATA WITH UNIQUE PATIENT IDS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0d921-d6a1-476c-a952-83bdf167ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD BOTH YEAR FILES\n",
    "# ============================================================================\n",
    "print(\"\\nüìÅ Step 1: Loading data from both years...\")\n",
    "\n",
    "# Load year 1401 data\n",
    "df_1401 = pd.read_excel(\"Results1401.xlsx\")\n",
    "print(f\"‚úì Year 1401: {len(df_1401)} records, {df_1401['PID'].nunique()} unique PIDs\")\n",
    "\n",
    "# Load year 1402 data\n",
    "df_1402 = pd.read_excel(\"Results1402.xlsx\")  # Update filename as needed\n",
    "print(f\"‚úì Year 1402: {len(df_1402)} records, {df_1402['PID'].nunique()} unique PIDs\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: CREATE UNIQUE IDENTIFIERS\n",
    "# ============================================================================\n",
    "print(\"\\nüîë Step 2: Creating unique patient identifiers...\")\n",
    "\n",
    "# Add year column to each dataset\n",
    "df_1401['Year'] = 1401\n",
    "df_1402['Year'] = 1402\n",
    "\n",
    "# Create unique patient ID by combining Year and PID\n",
    "# Format: \"YEAR_PID\" (e.g., \"1401_2\", \"1402_2\" are different patients)\n",
    "df_1401['UniqueID'] = df_1401['Year'].astype(str) + '_' + df_1401['PID'].astype(str)\n",
    "df_1402['UniqueID'] = df_1402['Year'].astype(str) + '_' + df_1402['PID'].astype(str)\n",
    "\n",
    "print(f\"‚úì Created unique IDs for year 1401 (e.g., {df_1401['UniqueID'].iloc[0]})\")\n",
    "print(f\"‚úì Created unique IDs for year 1402 (e.g., {df_1402['UniqueID'].iloc[0]})\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: COMBINE THE DATASETS\n",
    "# ============================================================================\n",
    "print(\"\\nüîÑ Step 3: Combining datasets...\")\n",
    "\n",
    "# Combine both dataframes\n",
    "df_combined = pd.concat([df_1401, df_1402], ignore_index=True)\n",
    "\n",
    "print(f\"‚úì Combined dataset: {len(df_combined)} total records\")\n",
    "print(f\"‚úì Total unique patients: {df_combined['UniqueID'].nunique()}\")\n",
    "print(f\"‚úì Years included: {df_combined['Year'].unique()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: PROCESS COMBINED DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüßπ Step 4: Processing combined data...\")\n",
    "\n",
    "def process_result(value):\n",
    "    \"\"\"Convert various result formats to numeric values\"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            if value.strip().lower() in ['*', 'negative', 'positive', '']:\n",
    "                return None\n",
    "            value = value.replace('<', '').replace('>', '').strip()\n",
    "            if '/' in value:\n",
    "                parts = value.split('/')\n",
    "                numeric_parts = []\n",
    "                for part in parts:\n",
    "                    try:\n",
    "                        numeric_parts.append(float(part.strip()))\n",
    "                    except:\n",
    "                        pass\n",
    "                if numeric_parts:\n",
    "                    return np.mean(numeric_parts)\n",
    "            value = value.replace(\",\", \".\")\n",
    "        return float(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Process Result column\n",
    "df_combined[\"Result\"] = df_combined[\"Result\"].apply(process_result)\n",
    "valid_results = df_combined[\"Result\"].notna().sum()\n",
    "print(f\"‚úì Processed results: {valid_results}/{len(df_combined)} valid numeric values\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: CREATE TARGET VARIABLE\n",
    "# ============================================================================\n",
    "print(\"\\nüéØ Step 5: Creating target variable based on HbA1c...\")\n",
    "\n",
    "# Create target for combined data\n",
    "df_combined[\"HbA1C_Flag\"] = df_combined.apply(\n",
    "    lambda row: 1 if row[\"TName\"] == \"Hb A1C\" and pd.notna(row[\"Result\"]) and row[\"Result\"] >= 6.5 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Map to patient level using UniqueID (not PID)\n",
    "pid_target = df_combined.groupby(\"UniqueID\")[\"HbA1C_Flag\"].max()\n",
    "df_combined[\"Target\"] = df_combined[\"UniqueID\"].map(pid_target)\n",
    "df_combined = df_combined.drop(columns=[\"HbA1C_Flag\"])\n",
    "\n",
    "# Check target distribution by year\n",
    "print(\"\\nTarget distribution by year:\")\n",
    "for year in [1401, 1402]:\n",
    "    year_data = df_combined[df_combined['Year'] == year]\n",
    "    target_dist = year_data.groupby('UniqueID')['Target'].first().value_counts()\n",
    "    print(f\"\\nYear {year}:\")\n",
    "    print(f\"  Non-diabetic (0): {target_dist.get(0, 0)} patients\")\n",
    "    print(f\"  Diabetic (1): {target_dist.get(1, 0)} patients\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: PIVOT COMBINED DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüìä Step 6: Pivoting combined data...\")\n",
    "\n",
    "# Group by UniqueID instead of PID\n",
    "df_grouped = df_combined.groupby(['UniqueID', 'TName', 'Target', 'Year'])['Result'].mean().reset_index()\n",
    "\n",
    "# Pivot with UniqueID\n",
    "df_pivot = df_grouped.pivot(index=['UniqueID', 'Target', 'Year'], \n",
    "                            columns='TName', \n",
    "                            values='Result').reset_index()\n",
    "\n",
    "print(f\"‚úì Pivoted data: {df_pivot.shape[0]} unique patients √ó {df_pivot.shape[1]-3} features\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: HANDLE MISSING VALUES\n",
    "# ============================================================================\n",
    "print(\"\\nüîß Step 7: Handling missing values...\")\n",
    "\n",
    "# Fill missing values with median per test\n",
    "for col in df_pivot.columns:\n",
    "    if col not in ['UniqueID', 'Target', 'Year']:\n",
    "        median_val = df_pivot[col].median()\n",
    "        if pd.notna(median_val):\n",
    "            df_pivot[col] = df_pivot[col].fillna(median_val)\n",
    "        else:\n",
    "            df_pivot[col] = df_pivot[col].fillna(0)\n",
    "\n",
    "print(\"‚úì Missing values filled with median per test\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: PREPARE FOR MACHINE LEARNING\n",
    "# ============================================================================\n",
    "print(\"\\nüéØ Step 8: Preparing for machine learning...\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df_pivot.drop(['UniqueID', 'Target', 'Year'], axis=1)\n",
    "y = df_pivot['Target']\n",
    "\n",
    "# Also keep year information for potential stratified splitting\n",
    "years = df_pivot['Year']\n",
    "unique_ids = df_pivot['UniqueID']\n",
    "\n",
    "print(f\"‚úì Feature matrix: {X.shape}\")\n",
    "print(f\"‚úì Target vector: {y.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: CREATE TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "print(\"\\n‚úÇÔ∏è Step 9: Creating train-test split...\")\n",
    "\n",
    "# Option 1: Random split (patients from both years in train and test)\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
    "    X, y, unique_ids,\n",
    "    test_size=0.2, \n",
    "    random_state=2, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Option 1 - Random Split:\")\n",
    "print(f\"Training: {len(X_train)} patients\")\n",
    "print(f\"Testing: {len(X_test)} patients\")\n",
    "\n",
    "# Option 2: Time-based split (train on 1401, test on 1402)\n",
    "train_mask = years == 1401\n",
    "test_mask = years == 1402\n",
    "\n",
    "X_train_time = X[train_mask]\n",
    "X_test_time = X[test_mask]\n",
    "y_train_time = y[train_mask]\n",
    "y_test_time = y[test_mask]\n",
    "\n",
    "print(\"\\nüìä Option 2 - Time-based Split:\")\n",
    "print(f\"Training (1401): {len(X_train_time)} patients\")\n",
    "print(f\"Testing (1402): {len(X_test_time)} patients\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: SAVE COMBINED DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüíæ Step 10: Saving processed data...\")\n",
    "\n",
    "# Save the combined pivoted data\n",
    "df_pivot.to_excel(\"combined_data_1401_1402_pivoted.xlsx\", index=False)\n",
    "print(\"‚úì Saved combined pivoted data\")\n",
    "\n",
    "# Save the combined raw data\n",
    "df_combined.to_excel(\"combined_data_1401_1402_raw.xlsx\", index=False)\n",
    "print(\"‚úì Saved combined raw data\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ DATA COMBINATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nCombined Statistics:\")\n",
    "print(f\"‚Ä¢ Total unique patients: {df_pivot['UniqueID'].nunique()}\")\n",
    "print(f\"‚Ä¢ Total features: {X.shape[1]}\")\n",
    "print(f\"‚Ä¢ Years included: 1401, 1402\")\n",
    "print(f\"‚Ä¢ Class distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\nüìù Important Notes:\")\n",
    "print(\"‚Ä¢ Each patient has a unique ID: YEAR_PID (e.g., '1401_2', '1402_2')\")\n",
    "print(\"‚Ä¢ PID=2 in 1401 and PID=2 in 1402 are treated as DIFFERENT patients\")\n",
    "print(\"‚Ä¢ You can use either random split or time-based split for training\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"1. Use X_train, X_test, y_train, y_test for model training\")\n",
    "print(\"2. Or use X_train_time, X_test_time for temporal validation\")\n",
    "print(\"3. The combined data has more samples for better model training\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Make variables available globally\n",
    "print(\"\\n‚úì Variables ready for use:\")\n",
    "print(\"  - X_train, X_test, y_train, y_test (random split)\")\n",
    "print(\"  - X_train_time, X_test_time, y_train_time, y_test_time (time split)\")\n",
    "print(\"  - df_combined (raw combined data)\")\n",
    "print(\"  - df_pivot (pivoted combined data)\")\n",
    "\n",
    "# Convert y_train to 1D array for sklearn\n",
    "y_train = np.ravel(y_train)\n",
    "y_train_time = np.ravel(y_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf75d01-66fe-461e-ad1e-db7af20a25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüìÅ Step 1: Loading data...\")\n",
    "df = pd.read_excel(\"Results1401.xlsx\")\n",
    "print(f\"‚úì Loaded {len(df)} records from {df['PID'].nunique()} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef4b76-36c3-4952-b090-1289205b5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VERIFY DATA IS LOADED\n",
    "# ============================================================================\n",
    "try:\n",
    "    print(f\"\\n‚úì Data check:\")\n",
    "    print(f\"  X_train shape: {X_train.shape}\")\n",
    "    print(f\"  X_test shape: {X_test.shape}\")\n",
    "    print(f\"  y_train shape: {y_train.shape}\")\n",
    "    print(f\"  y_test shape: {y_test.shape}\")\n",
    "except NameError:\n",
    "    print(\"\\n‚ö†Ô∏è ERROR: Data not found!\")\n",
    "    print(\"Please run the preprocessing code first to create X_train, X_test, y_train, y_test\")\n",
    "    print(\"Then run this cell again.\")\n",
    "\n",
    "# Store results for comparison\n",
    "model_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5473da7-c266-4208-8131-f44717a8bd5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: CLEAN RESULT VALUES\n",
    "# ============================================================================\n",
    "print(\"\\nüßπ Step 2: Cleaning Result column...\")\n",
    "\n",
    "def process_result(value):\n",
    "    \"\"\"Convert various result formats to numeric values\"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            # Handle special markers\n",
    "            if value.strip().lower() in ['*', 'negative', 'positive', '']:\n",
    "                return None\n",
    "            # Remove comparison operators\n",
    "            value = value.replace('<', '').replace('>', '').strip()\n",
    "            # Handle fractions (e.g., \"71/68\" -> average)\n",
    "            if '/' in value:\n",
    "                parts = value.split('/')\n",
    "                numeric_parts = []\n",
    "                for part in parts:\n",
    "                    try:\n",
    "                        numeric_parts.append(float(part.strip()))\n",
    "                    except:\n",
    "                        pass\n",
    "                if numeric_parts:\n",
    "                    return np.mean(numeric_parts)\n",
    "            # Replace decimal separator if needed\n",
    "            value = value.replace(\",\", \".\")\n",
    "        return float(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df[\"Result\"] = df[\"Result\"].apply(process_result)\n",
    "valid_results = df[\"Result\"].notna().sum()\n",
    "print(f\"‚úì Processed results: {valid_results}/{len(df)} valid numeric values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6e439-9a1e-445b-a7fc-9e8c644919ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: CREATE TARGET VARIABLE\n",
    "# ============================================================================\n",
    "print(\"\\nüéØ Step 3: Creating target variable (HbA1c >= 6.5)...\")\n",
    "\n",
    "# Identify diabetic patients based on HbA1c\n",
    "df[\"HbA1C_Flag\"] = df.apply(\n",
    "    lambda row: 1 if row[\"TName\"] == \"Hb A1C\" and pd.notna(row[\"Result\"]) and row[\"Result\"] >= 6.5 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Map to patient level\n",
    "pid_target = df.groupby(\"PID\")[\"HbA1C_Flag\"].max()\n",
    "df[\"Target\"] = df[\"PID\"].map(pid_target)\n",
    "df = df.drop(columns=[\"HbA1C_Flag\"])\n",
    "\n",
    "target_dist = df.groupby('PID')['Target'].first().value_counts()\n",
    "print(f\"‚úì Target distribution:\")\n",
    "print(f\"  - Non-diabetic (Target=0): {target_dist.get(0, 0)} patients\")\n",
    "print(f\"  - Diabetic (Target=1): {target_dist.get(1, 0)} patients\")\n",
    "\n",
    "if target_dist.get(1, 0) == 0:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No diabetic patients found. Check if 'Hb A1C' test name is correct.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2968815-2920-492f-a355-c2d38ec6654b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: PIVOT TO WIDE FORMAT\n",
    "# ============================================================================\n",
    "print(\"\\nüîÑ Step 4: Pivoting data (patients as rows, tests as columns)...\")\n",
    "\n",
    "# Group by PID and TName, taking mean of duplicate tests\n",
    "df_grouped = df.groupby(['PID', 'TName', 'Target'])['Result'].mean().reset_index()\n",
    "\n",
    "# Pivot to wide format\n",
    "df_pivot = df_grouped.pivot(index=['PID', 'Target'], columns='TName', values='Result').reset_index()\n",
    "\n",
    "print(f\"‚úì Pivoted data shape: {df_pivot.shape[0]} patients √ó {df_pivot.shape[1]-2} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dac064-2c9b-4309-b56d-0037eab80514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: HANDLE MISSING VALUES\n",
    "# ============================================================================\n",
    "print(\"\\nüîß Step 5: Handling missing values...\")\n",
    "\n",
    "# Calculate missing percentage for each test\n",
    "missing_before = df_pivot.isna().sum()\n",
    "high_missing = missing_before[missing_before > len(df_pivot) * 0.5]\n",
    "\n",
    "if len(high_missing) > 0:\n",
    "    print(f\"‚ö†Ô∏è  Tests with >50% missing values: {list(high_missing.index[:5])}...\")\n",
    "\n",
    "# Fill missing values with median (best practice for medical data)\n",
    "for col in df_pivot.columns:\n",
    "    if col not in ['PID', 'Target']:\n",
    "        median_val = df_pivot[col].median()\n",
    "        if pd.notna(median_val):\n",
    "            df_pivot[col] = df_pivot[col].fillna(median_val)\n",
    "        else:\n",
    "            df_pivot[col] = df_pivot[col].fillna(0)\n",
    "\n",
    "print(f\"‚úì Missing values filled with median per test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69109d7b-e600-49dd-9b1c-a2a246c0fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: PREPARE FEATURES AND TARGET\n",
    "# ============================================================================\n",
    "print(\"\\nüìä Step 6: Preparing features and target...\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df_pivot.drop(['PID', 'Target'], axis=1)\n",
    "y = df_pivot['Target']\n",
    "\n",
    "# Remove constant features (same value for all patients)\n",
    "constant_features = X.columns[X.nunique() <= 1]\n",
    "if len(constant_features) > 0:\n",
    "    print(f\"‚ö†Ô∏è  Removing {len(constant_features)} constant features\")\n",
    "    X = X.drop(columns=constant_features)\n",
    "\n",
    "print(f\"‚úì Final feature matrix: {X.shape[0]} patients √ó {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95dd76-d53d-4e67-82b2-50d4203c294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: TRAIN-TEST SPLIT (BEST PRACTICE: STRATIFIED)\n",
    "# ============================================================================\n",
    "print(\"\\n‚úÇÔ∏è Step 7: Train-test split (stratified to maintain class balance)...\")\n",
    "\n",
    "# BEST PRACTICE: Stratified split ensures both classes in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=2, \n",
    "    stratify=y  # This ensures proportional representation of both classes\n",
    ")\n",
    "\n",
    "print(f\"‚úì Training set: {len(X_train)} patients\")\n",
    "print(f\"  - Non-diabetic: {(y_train == 0).sum()} ({(y_train == 0).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  - Diabetic: {(y_train == 1).sum()} ({(y_train == 1).sum()/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"‚úì Test set: {len(X_test)} patients\")\n",
    "print(f\"  - Non-diabetic: {(y_test == 0).sum()} ({(y_test == 0).sum()/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  - Diabetic: {(y_test == 1).sum()} ({(y_test == 1).sum()/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f40a1b-e2cc-43f4-8937-afbea4492f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: FEATURE SCALING (OPTIONAL BUT RECOMMENDED)\n",
    "# ============================================================================\n",
    "print(\"\\n‚öñÔ∏è Step 8: Standardizing features (mean=0, std=1)...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "print(\"‚úì Features standardized (important for SVM, KNN)\")\n",
    "\n",
    "# Get feature names for later use\n",
    "feature_names = X_test.columns.tolist()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: SAVE PROCESSED DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüíæ Step 9: Saving processed data...\")\n",
    "\n",
    "# Save the pivoted data\n",
    "df_pivot.to_excel(\"processed_data_pivoted.xlsx\", index=False)\n",
    "print(\"‚úì Saved processed data to 'processed_data_pivoted.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2654a0-7a15-4a32-baf3-a1be741b455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PREPROCESSING COMPLETE - DATA READY FOR MACHINE LEARNING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã SUMMARY:\")\n",
    "print(f\"‚Ä¢ Total patients: {len(df_pivot)}\")\n",
    "print(f\"‚Ä¢ Total features: {X.shape[1]}\")\n",
    "print(f\"‚Ä¢ Class balance: {y.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"‚Ä¢ Train-test split: 80%-20%\")\n",
    "print(f\"‚Ä¢ Both classes present in both sets: ‚úì\")\n",
    "\n",
    "print(\"\\nüéì WHY THIS IS BEST PRACTICE:\")\n",
    "print(\"1. Stratified split maintains class proportions in both sets\")\n",
    "print(\"2. Model learns from both diabetic AND non-diabetic patterns\")\n",
    "print(\"3. Test set reflects real-world distribution\")\n",
    "print(\"4. Metrics (accuracy, precision, recall) are meaningful\")\n",
    "print(\"5. Model can generalize to new patients\")\n",
    "\n",
    "# Convert y_train to 1D array as required by sklearn\n",
    "y_train = np.ravel(y_train)\n",
    "print(f\"\\n‚úì y_train converted to 1D array shape: {y_train.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ READY TO USE IN YOUR NOTEBOOK\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nVariables ready for your models:\")\n",
    "print(\"‚Ä¢ X_train, X_test, y_train, y_test - for tree-based models (RF, XGBoost)\")\n",
    "print(\"‚Ä¢ X_train_scaled, X_test_scaled - for distance-based models (SVM, KNN)\")\n",
    "print(\"‚Ä¢ feature_names - for feature importance analysis\")\n",
    "\n",
    "print(\"\\nüìù Now you can run your ML models directly:\")\n",
    "print(\"-\"*40)\n",
    "print(\"# Your existing code will work as-is:\")\n",
    "print(\"LR.fit(X_train, y_train)\")\n",
    "print(\"y_pred = LR.predict(X_test)\")\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9f762-3edf-4fad-b9ac-5e5b846b1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE MACHINE LEARNING MODELS FOR T2DM PREDICTION\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Store results for comparison\n",
    "model_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481bc70-4495-4f3c-aa36-a5c57637d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3.1 LOGISTIC REGRESSION (if not already done)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3.1 LOGISTIC REGRESSION (LR)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create and train LR model\n",
    "LR = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Cross-validation\n",
    "cv = KFold(n_splits=10, random_state=2, shuffle=True)\n",
    "scores = cross_val_score(LR, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy for training: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# Fit and predict\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred_lr = LR.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print('Accuracy for testing: %.4f' % accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, digits=4))\n",
    "\n",
    "cf_matrix_LR = confusion_matrix(y_test, y_pred_lr)\n",
    "model_results['LR'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'model': LR,\n",
    "    'predictions': y_pred_lr\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f6445-a5e2-483d-abea-8b8e57533033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3.2 KNN (K-Nearest Neighbors)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3.2 K-NEAREST NEIGHBORS (KNN)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Grid search for best parameters\n",
    "params_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(knn, params_knn, cv=10, scoring='accuracy')\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_knn.best_params_}\")\n",
    "\n",
    "# Create model with best parameters\n",
    "KNN = KNeighborsClassifier(**grid_knn.best_params_)\n",
    "\n",
    "# Cross-validation\n",
    "cv = KFold(n_splits=10, random_state=2, shuffle=True)\n",
    "scores = cross_val_score(KNN, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy for training: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# Fit and predict\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred_knn = KNN.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print('Accuracy for testing: %.4f' % accuracy_score(y_test, y_pred_knn))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, digits=4))\n",
    "\n",
    "cf_matrix_KNN = confusion_matrix(y_test, y_pred_knn)\n",
    "model_results['KNN'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_knn),\n",
    "    'model': KNN,\n",
    "    'predictions': y_pred_knn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5bda9-0fc3-43b8-ad6e-061a23ae9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3.3 SVM (Support Vector Machine)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3.3 SUPPORT VECTOR MACHINE (SVM)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# Use scaled data for SVM\n",
    "SVM = svm.SVC(probability=True, kernel='rbf')\n",
    "\n",
    "# Cross-validation\n",
    "cv = KFold(n_splits=10, random_state=2, shuffle=True)\n",
    "scores = cross_val_score(SVM, X_train_scaled, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy for training: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# Fit and predict (using scaled data)\n",
    "SVM.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = SVM.predict(X_test_scaled)\n",
    "\n",
    "# Results\n",
    "print('Accuracy for testing: %.4f' % accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, digits=4))\n",
    "\n",
    "cf_matrix_SVM = confusion_matrix(y_test, y_pred_svm)\n",
    "model_results['SVM'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_svm),\n",
    "    'model': SVM,\n",
    "    'predictions': y_pred_svm\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366e11c-c1c2-490d-a6a1-b38e59dd84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3.4 NAIVE BAYES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3.4 NAIVE BAYES (NB)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB = GaussianNB()\n",
    "\n",
    "# Cross-validation\n",
    "cv = KFold(n_splits=10, random_state=2, shuffle=True)\n",
    "scores = cross_val_score(NB, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy for training: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# Fit and predict\n",
    "NB.fit(X_train, y_train)\n",
    "y_pred_nb = NB.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print('Accuracy for testing: %.4f' % accuracy_score(y_test, y_pred_nb))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb, digits=4))\n",
    "\n",
    "cf_matrix_NB = confusion_matrix(y_test, y_pred_nb)\n",
    "model_results['NB'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_nb),\n",
    "    'model': NB,\n",
    "    'predictions': y_pred_nb\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83078b8f-9010-41bf-a9c3-1f176523d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3.5 DECISION TREE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3.5 DECISION TREE (DT)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier(random_state=2, max_depth=10, min_samples_split=5)\n",
    "\n",
    "# Cross-validation\n",
    "cv = KFold(n_splits=10, random_state=2, shuffle=True)\n",
    "scores = cross_val_score(DT, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy for training: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# Fit and predict\n",
    "DT.fit(X_train, y_train)\n",
    "y_pred_dt = DT.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print('Accuracy for testing: %.4f' % accuracy_score(y_test, y_pred_dt))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, digits=4))\n",
    "\n",
    "cf_matrix_DT = confusion_matrix(y_test, y_pred_dt)\n",
    "model_results['DT'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_dt),\n",
    "    'model': DT,\n",
    "    'predictions': y_pred_dt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1463a2d-0f70-4713-b7d2-c205daaac519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3.6 RANDOM FOREST\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3.6 RANDOM FOREST (RF)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Grid search for best parameters\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_grid = RandomForestClassifier(random_state=2)\n",
    "grid_rf = GridSearchCV(rf_grid, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_rf.best_params_}\")\n",
    "\n",
    "# Create model with best parameters\n",
    "RF = RandomForestClassifier(**grid_rf.best_params_, random_state=2)\n",
    "\n",
    "# Cross-validation\n",
    "cv = KFold(n_splits=10, random_state=2, shuffle=True)\n",
    "scores = cross_val_score(RF, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy for training: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# Fit and predict\n",
    "RF.fit(X_train, y_train)\n",
    "y_pred_rf = RF.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print('Accuracy for testing: %.4f' % accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=4))\n",
    "\n",
    "cf_matrix_RF = confusion_matrix(y_test, y_pred_rf)\n",
    "model_results['RF'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'model': RF,\n",
    "    'predictions': y_pred_rf\n",
    "}\n",
    "\n",
    "# Feature Importance for Random Forest\n",
    "importances = RF.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_features = 10\n",
    "\n",
    "print(f\"\\nTop {top_features} Important Features:\")\n",
    "for i in range(min(top_features, len(indices))):\n",
    "    print(f\"{i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068730f-a4ae-4930-87f2-a3dc51a80db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e53ea-2034-478e-933a-ad6faa143bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3.7 XGBOOST\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import mean, std\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"XGBOOST WITH DATA VALIDATION\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218764a-4242-429c-8863-9571ef2217b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: VALIDATE AND FIX DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüìã Checking data format...\")\n",
    "\n",
    "# Check data shapes\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Ensure y_train is 1D array\n",
    "if len(y_train.shape) > 1:\n",
    "    print(\"‚ö†Ô∏è Converting y_train to 1D array...\")\n",
    "    y_train = np.ravel(y_train)\n",
    "    print(f\"‚úì New y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Check for NaN values\n",
    "if X_train.isna().any().any() if hasattr(X_train, 'isna') else np.isnan(X_train).any():\n",
    "    print(\"‚ö†Ô∏è Found NaN values in X_train. Filling with 0...\")\n",
    "    if hasattr(X_train, 'fillna'):\n",
    "        X_train = X_train.fillna(0)\n",
    "        X_test = X_test.fillna(0)\n",
    "    else:\n",
    "        X_train = np.nan_to_num(X_train)\n",
    "        X_test = np.nan_to_num(X_test)\n",
    "    print(\"‚úì NaN values filled\")\n",
    "\n",
    "# Convert to numpy arrays if they're DataFrames\n",
    "if hasattr(X_train, 'values'):\n",
    "    X_train_np = X_train.values\n",
    "    X_test_np = X_test.values\n",
    "else:\n",
    "    X_train_np = X_train\n",
    "    X_test_np = X_test\n",
    "\n",
    "# Ensure y is integer type for classification\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "print(\"\\n‚úì Data validation complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904c981-f757-4675-a8c9-53fce9b98fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: TRAIN XGBOOST MODEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING XGBOOST MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create XGBoost classifier with proper parameters\n",
    "XGB = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.3,\n",
    "    objective='binary:logistic',\n",
    "    random_state=2,\n",
    "    use_label_encoder=False,  # Prevents warning\n",
    "    eval_metric='logloss',     # Prevents warning\n",
    "    n_jobs=1                    # Use single thread for stability\n",
    ")\n",
    "\n",
    "# Try cross-validation with error handling\n",
    "try:\n",
    "    print(\"\\nPerforming cross-validation...\")\n",
    "    cv = KFold(n_splits=10, random_state=2, shuffle=True)\n",
    "    scores = cross_val_score(XGB, X_train_np, y_train, scoring='accuracy', cv=cv, n_jobs=1)\n",
    "    print('‚úì Accuracy for training: %.4f (%.4f)' % (mean(scores), std(scores)))\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Cross-validation failed: {e}\")\n",
    "    print(\"Proceeding with simple train-test evaluation...\")\n",
    "\n",
    "# Fit the model\n",
    "print(\"\\nTraining model...\")\n",
    "XGB.fit(X_train_np, y_train)\n",
    "print(\"‚úì Model trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = XGB.predict(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2704559-a9cd-41e8-b78d-5728622e31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: EVALUATE MODEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f'\\nAccuracy for testing: {accuracy:.4f}')\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, digits=4))\n",
    "\n",
    "# Extract confusion matrix values\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nDetailed Results:\")\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "if (tp + fp) > 0:\n",
    "    precision = tp / (tp + fp)\n",
    "else:\n",
    "    precision = 0\n",
    "\n",
    "if (tp + fn) > 0:\n",
    "    recall = tp / (tp + fn)\n",
    "else:\n",
    "    recall = 0\n",
    "\n",
    "if (precision + recall) > 0:\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "else:\n",
    "    f1_score = 0\n",
    "\n",
    "print(f\"\\nPrecision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239e84e-e450-4703-85c0-67f3ad8b5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ALTERNATIVE: SIMPLIFIED XGBOOST (if above still fails)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALTERNATIVE APPROACH (if needed)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "If the above code still fails, try this simplified version:\n",
    "\n",
    "```python\n",
    "# Simple XGBoost without cross-validation\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "y_train_np = np.array(y_train).astype(int)\n",
    "y_test_np = np.array(y_test).astype(int)\n",
    "\n",
    "# Create and train model\n",
    "xgb_simple = XGBClassifier(random_state=2)\n",
    "xgb_simple.fit(X_train_np, y_train_np)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = xgb_simple.predict(X_test_np)\n",
    "accuracy = accuracy_score(y_test_np, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úì XGBoost training completed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1dcf1-72fa-4017-a8a7-6fcb6cf89910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE MODEL COMPARISON FOR T2DM PREDICTION\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, confusion_matrix, roc_curve, auc,\n",
    "                           matthews_corrcoef)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON ANALYSIS\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965cace-68c9-4601-9070-c258a9927a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: COLLECT ALL MODEL RESULTS\n",
    "# ============================================================================\n",
    "print(\"\\nüìä Collecting model results...\")\n",
    "\n",
    "# Dictionary to store all models and their predictions\n",
    "# Make sure you have run all models before this\n",
    "models = {\n",
    "    'Logistic Regression': {'model': LR, 'predictions': y_pred_lr, 'abbrev': 'LR'},\n",
    "    'KNN': {'model': KNN, 'predictions': y_pred_knn, 'abbrev': 'KNN'},\n",
    "    'SVM': {'model': SVM, 'predictions': y_pred_svm, 'abbrev': 'SVM'},\n",
    "    'Naive Bayes': {'model': NB, 'predictions': y_pred_nb, 'abbrev': 'NB'},\n",
    "    'Decision Tree': {'model': DT, 'predictions': y_pred_dt, 'abbrev': 'DT'},\n",
    "    'Random Forest': {'model': RF, 'predictions': y_pred_rf, 'abbrev': 'RF'},\n",
    "    'XGBoost': {'model': XGB, 'predictions': y_pred_xgb, 'abbrev': 'XGB'}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45578f-fc4c-4179-8d0b-d68dc4d91ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: CALCULATE COMPREHENSIVE METRICS\n",
    "# ============================================================================\n",
    "print(\"\\nüìà Calculating performance metrics...\")\n",
    "\n",
    "results = []\n",
    "for name, model_info in models.items():\n",
    "    y_pred_model = model_info['predictions']\n",
    "    \n",
    "    # Calculate confusion matrix components\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_model).ravel()\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred_model)\n",
    "    precision = precision_score(y_test, y_pred_model, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_model, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_model, zero_division=0)\n",
    "    \n",
    "    # Additional metrics\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n",
    "    mcc = matthews_corrcoef(y_test, y_pred_model)  # Matthews Correlation Coefficient\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Abbreviation': model_info['abbrev'],\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall (Sensitivity)': recall,\n",
    "        'Specificity': specificity,\n",
    "        'F1-Score': f1,\n",
    "        'NPV': npv,\n",
    "        'MCC': mcc,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a3cc7-649c-4363-8244-d3f8fc804e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: DISPLAY COMPARISON TABLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display main metrics\n",
    "print(\"\\nüìã Performance Metrics (sorted by Accuracy):\")\n",
    "print(\"-\" * 80)\n",
    "display_cols = ['Model', 'Accuracy', 'Precision', 'Recall (Sensitivity)', \n",
    "                'Specificity', 'F1-Score', 'MCC']\n",
    "print(results_df[display_cols].round(4).to_string(index=False))\n",
    "\n",
    "# Best model identification\n",
    "best_model = results_df.iloc[0]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"üèÜ BEST MODEL: {best_model['Model']}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy: {best_model['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {best_model['Precision']:.4f}\")\n",
    "print(f\"Recall: {best_model['Recall (Sensitivity)']:.4f}\")\n",
    "print(f\"F1-Score: {best_model['F1-Score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f094a-9c4d-480d-919f-4e40129d9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: VISUALIZATIONS\n",
    "# ============================================================================\n",
    "print(\"\\nüìä Generating visualizations...\")\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# --- 1. Bar Chart: Accuracy Comparison ---\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(results_df)))\n",
    "bars = ax1.bar(results_df['Abbreviation'], results_df['Accuracy'], color=colors)\n",
    "ax1.set_xlabel('Model', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# --- 2. Multi-metric Comparison ---\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall (Sensitivity)', 'F1-Score']\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    offset = (i - len(metrics_to_plot)/2) * width + width/2\n",
    "    ax2.bar(x + offset, results_df[metric], width, label=metric)\n",
    "\n",
    "ax2.set_xlabel('Model', fontsize=12)\n",
    "ax2.set_ylabel('Score', fontsize=12)\n",
    "ax2.set_title('Multi-Metric Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(results_df['Abbreviation'])\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# --- 3. Confusion Matrix Heatmap (Best Model) ---\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "best_model_name = best_model['Model']\n",
    "best_pred = models[best_model_name]['predictions']\n",
    "cm_best = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Diabetic', 'Diabetic'],\n",
    "            yticklabels=['Non-Diabetic', 'Diabetic'], ax=ax3)\n",
    "ax3.set_title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('True Label', fontsize=12)\n",
    "ax3.set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "# --- 4. ROC Curves ---\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "roc_data = []\n",
    "\n",
    "for name, model_info in models.items():\n",
    "    model = model_info['model']\n",
    "    \n",
    "    # Get probability predictions\n",
    "    try:\n",
    "        if name == 'SVM':\n",
    "            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if 'X_test_scaled' in globals() else model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    except:\n",
    "        # If predict_proba not available, use decision_function\n",
    "        try:\n",
    "            if name == 'SVM':\n",
    "                y_pred_proba = model.decision_function(X_test_scaled) if 'X_test_scaled' in globals() else model.decision_function(X_test)\n",
    "            else:\n",
    "                y_pred_proba = model.decision_function(X_test)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_data.append({'Model': name, 'AUC': roc_auc})\n",
    "    \n",
    "    ax4.plot(fpr, tpr, label=f'{model_info[\"abbrev\"]} (AUC = {roc_auc:.3f})', linewidth=2)\n",
    "\n",
    "ax4.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
    "ax4.set_xlim([0.0, 1.0])\n",
    "ax4.set_ylim([0.0, 1.05])\n",
    "ax4.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax4.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax4.set_title('ROC Curves - All Models', fontsize=14, fontweight='bold')\n",
    "ax4.legend(loc=\"lower right\", fontsize=10)\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "# --- 5. Precision-Recall Comparison ---\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "ax5.scatter(results_df['Recall (Sensitivity)'], results_df['Precision'], \n",
    "           s=results_df['F1-Score']*500, alpha=0.6, c=range(len(results_df)), cmap='viridis')\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    ax5.annotate(row['Abbreviation'], \n",
    "                (row['Recall (Sensitivity)'], row['Precision']),\n",
    "                fontsize=10, ha='center')\n",
    "\n",
    "ax5.set_xlabel('Recall (Sensitivity)', fontsize=12)\n",
    "ax5.set_ylabel('Precision', fontsize=12)\n",
    "ax5.set_title('Precision vs Recall (bubble size = F1-Score)', fontsize=14, fontweight='bold')\n",
    "ax5.grid(alpha=0.3)\n",
    "ax5.set_xlim([-0.05, 1.05])\n",
    "ax5.set_ylim([-0.05, 1.05])\n",
    "\n",
    "# --- 6. Error Analysis ---\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "error_data = pd.DataFrame({\n",
    "    'False Positives': results_df['FP'].values,\n",
    "    'False Negatives': results_df['FN'].values\n",
    "}, index=results_df['Abbreviation'].values)\n",
    "\n",
    "error_data.plot(kind='bar', ax=ax6, color=['#ff6b6b', '#4ecdc4'])\n",
    "ax6.set_xlabel('Model', fontsize=12)\n",
    "ax6.set_ylabel('Number of Errors', fontsize=12)\n",
    "ax6.set_title('Error Distribution by Model', fontsize=14, fontweight='bold')\n",
    "ax6.legend(title='Error Type')\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "plt.setp(ax6.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_complete.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualizations saved as 'model_comparison_complete.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bf45c-5357-421b-bf0e-6ae67a62af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: STATISTICAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# AUC Ranking\n",
    "if roc_data:\n",
    "    auc_df = pd.DataFrame(roc_data).sort_values('AUC', ascending=False)\n",
    "    print(\"\\nüìä AUC Ranking:\")\n",
    "    print(\"-\" * 40)\n",
    "    for idx, row in auc_df.iterrows():\n",
    "        print(f\"{row['Model']}: {row['AUC']:.4f}\")\n",
    "\n",
    "# Model consensus\n",
    "print(\"\\nü§ù Model Consensus Analysis:\")\n",
    "print(\"-\" * 40)\n",
    "agreement_matrix = np.zeros((len(y_test), len(models)))\n",
    "for i, (name, model_info) in enumerate(models.items()):\n",
    "    agreement_matrix[:, i] = model_info['predictions']\n",
    "\n",
    "consensus = np.mean(agreement_matrix, axis=1)\n",
    "print(f\"Average agreement rate: {np.mean(consensus == consensus.round()):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd9ee3-a853-4658-a9a8-0e4ece252afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: SAVE RESULTS\n",
    "# ============================================================================\n",
    "print(\"\\nüíæ Saving results...\")\n",
    "\n",
    "# Save detailed results\n",
    "results_df.to_csv('model_comparison_detailed.csv', index=False)\n",
    "print(\"‚úì Detailed results saved to 'model_comparison_detailed.csv'\")\n",
    "\n",
    "# Save summary\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': ['Best Model', 'Best Accuracy', 'Best F1-Score', 'Best AUC'],\n",
    "    'Value': [\n",
    "        best_model['Model'],\n",
    "        f\"{best_model['Accuracy']:.4f}\",\n",
    "        f\"{best_model['F1-Score']:.4f}\",\n",
    "        f\"{auc_df.iloc[0]['AUC']:.4f}\" if roc_data else 'N/A'\n",
    "    ]\n",
    "})\n",
    "summary.to_csv('model_comparison_summary.csv', index=False)\n",
    "print(\"‚úì Summary saved to 'model_comparison_summary.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ MODEL COMPARISON COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nKey findings:\")\n",
    "print(f\"‚Ä¢ Best overall model: {best_model['Model']}\")\n",
    "print(f\"‚Ä¢ Highest accuracy: {best_model['Accuracy']:.4f}\")\n",
    "print(f\"‚Ä¢ Most consistent: {results_df.loc[results_df['MCC'].idxmax(), 'Model']} (highest MCC)\")\n",
    "print(f\"‚Ä¢ Best for avoiding false positives: {results_df.loc[results_df['Precision'].idxmax(), 'Model']}\")\n",
    "print(f\"‚Ä¢ Best for catching all diabetics: {results_df.loc[results_df['Recall (Sensitivity)'].idxmax(), 'Model']}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce57c486-692d-4de0-8c46-31fdf1e7bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KERAS DEEP NEURAL NETWORK (DNN) FOR T2DM PREDICTION\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import Keras/TensorFlow\n",
    "try:\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    print(\"‚úì TensorFlow/Keras imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è TensorFlow not installed. Installing...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tensorflow\"])\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3.8 KERAS DEEP NEURAL NETWORK (DNN)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: DATA PREPARATION\n",
    "# ============================================================================\n",
    "print(\"\\nüìä Preparing data for DNN...\")\n",
    "\n",
    "# Check if scaled data exists (recommended for neural networks)\n",
    "try:\n",
    "    X_train_dnn = X_train_scaled.values if hasattr(X_train_scaled, 'values') else X_train_scaled\n",
    "    X_test_dnn = X_test_scaled.values if hasattr(X_test_scaled, 'values') else X_test_scaled\n",
    "    print(\"‚úì Using scaled data (recommended for DNN)\")\n",
    "except:\n",
    "    # If scaled data doesn't exist, scale it now\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_dnn = scaler.fit_transform(X_train)\n",
    "    X_test_dnn = scaler.transform(X_test)\n",
    "    print(\"‚úì Data scaled for DNN\")\n",
    "\n",
    "# Ensure y is numpy array and correct shape\n",
    "y_train_dnn = np.array(y_train).astype(int)\n",
    "y_test_dnn = np.array(y_test).astype(int)\n",
    "\n",
    "# Get input dimension\n",
    "input_dim = X_train_dnn.shape[1]\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Training samples: {X_train_dnn.shape[0]}\")\n",
    "print(f\"Test samples: {X_test_dnn.shape[0]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: BUILD DNN MODEL\n",
    "# ============================================================================\n",
    "print(\"\\nüèóÔ∏è Building DNN architecture...\")\n",
    "\n",
    "def create_dnn_model(input_dim, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Create a Deep Neural Network for binary classification\n",
    "    \n",
    "    Architecture:\n",
    "    - Input layer\n",
    "    - Hidden layer 1: 128 neurons with ReLU\n",
    "    - Dropout layer: 0.3\n",
    "    - Hidden layer 2: 64 neurons with ReLU\n",
    "    - Batch Normalization\n",
    "    - Dropout layer: 0.2\n",
    "    - Hidden layer 3: 32 neurons with ReLU\n",
    "    - Output layer: 1 neuron with sigmoid (binary classification)\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential([\n",
    "        # First hidden layer\n",
    "        Dense(128, activation='relu', input_dim=input_dim, \n",
    "              kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Second hidden layer\n",
    "        Dense(64, activation='relu', \n",
    "              kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Third hidden layer\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "DNN = create_dnn_model(input_dim)\n",
    "\n",
    "# Display model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(\"-\" * 50)\n",
    "DNN.summary()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: TRAIN MODEL WITH CALLBACKS\n",
    "# ============================================================================\n",
    "print(\"\\nüéØ Training DNN model...\")\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = DNN.fit(\n",
    "    X_train_dnn, y_train_dnn,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=0  # Set to 1 to see training progress\n",
    ")\n",
    "\n",
    "print(f\"‚úì Training completed in {len(history.history['loss'])} epochs\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: EVALUATE MODEL\n",
    "# ============================================================================\n",
    "print(\"\\nüìà Evaluating DNN performance...\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dnn_prob = DNN.predict(X_test_dnn).flatten()\n",
    "y_pred_dnn = (y_pred_dnn_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_dnn = accuracy_score(y_test_dnn, y_pred_dnn)\n",
    "precision_dnn = precision_score(y_test_dnn, y_pred_dnn, zero_division=0)\n",
    "recall_dnn = recall_score(y_test_dnn, y_pred_dnn, zero_division=0)\n",
    "f1_dnn = f1_score(y_test_dnn, y_pred_dnn, zero_division=0)\n",
    "\n",
    "print(f'\\nAccuracy for testing: {accuracy_dnn:.4f}')\n",
    "print(f'Precision: {precision_dnn:.4f}')\n",
    "print(f'Recall: {recall_dnn:.4f}')\n",
    "print(f'F1-Score: {f1_dnn:.4f}')\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_dnn = confusion_matrix(y_test_dnn, y_pred_dnn)\n",
    "print(cm_dnn)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_dnn, y_pred_dnn, digits=4))\n",
    "\n",
    "# Store confusion matrix\n",
    "cf_matrix_DNN = cm_dnn\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: CROSS-VALIDATION (Optional - takes longer)\n",
    "# ============================================================================\n",
    "print(\"\\nüîÑ Performing cross-validation (this may take a minute)...\")\n",
    "\n",
    "# Simplified cross-validation\n",
    "cv_scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_dnn), 1):\n",
    "    # Create a new model for each fold\n",
    "    model_cv = create_dnn_model(input_dim)\n",
    "    \n",
    "    # Get fold data\n",
    "    X_fold_train, X_fold_val = X_train_dnn[train_idx], X_train_dnn[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train_dnn[train_idx], y_train_dnn[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model_cv.fit(\n",
    "        X_fold_train, y_fold_train,\n",
    "        epochs=50,  # Fewer epochs for CV\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_fold = (model_cv.predict(X_fold_val).flatten() > 0.5).astype(int)\n",
    "    fold_accuracy = accuracy_score(y_fold_val, y_pred_fold)\n",
    "    cv_scores.append(fold_accuracy)\n",
    "    print(f\"Fold {fold}: {fold_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nCross-validation accuracy: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: VISUALIZE TRAINING HISTORY\n",
    "# ============================================================================\n",
    "print(\"\\nüìä Generating training visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0].set_title('Model Accuracy Over Epochs')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot training & validation loss\n",
    "axes[1].plot(history.history['loss'], label='Training Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_title('Model Loss Over Epochs')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dnn_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training history saved as 'dnn_training_history.png'\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: ROC CURVE\n",
    "# ============================================================================\n",
    "print(\"\\nüìà Generating ROC curve...\")\n",
    "\n",
    "fpr_dnn, tpr_dnn, _ = roc_curve(y_test_dnn, y_pred_dnn_prob)\n",
    "roc_auc_dnn = auc(fpr_dnn, tpr_dnn)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_dnn, tpr_dnn, color='darkorange', lw=2, \n",
    "         label=f'DNN ROC curve (AUC = {roc_auc_dnn:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Deep Neural Network')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('dnn_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì ROC curve saved. AUC: {roc_auc_dnn:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: ADD TO MODEL COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\nüîÑ Adding DNN to model comparison...\")\n",
    "\n",
    "# Make sure the model and predictions are available globally\n",
    "globals()['DNN'] = DNN\n",
    "globals()['y_pred_dnn'] = y_pred_dnn\n",
    "\n",
    "print(\"‚úì DNN model saved as 'DNN'\")\n",
    "print(\"‚úì Predictions saved as 'y_pred_dnn'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEEP NEURAL NETWORK TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Final Test Accuracy: {accuracy_dnn:.4f}\")\n",
    "print(f\"Final Test F1-Score: {f1_dnn:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_dnn:.4f}\")\n",
    "print(\"\\nModel is ready for comparison with other algorithms.\")\n",
    "print(\"You can now include DNN in your model comparison by running the comparison code again.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
